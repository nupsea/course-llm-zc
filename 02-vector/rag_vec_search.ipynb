{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79ef896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import  TextEmbedding\n",
    "\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23428e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "docs = []\n",
    "for c in documents_raw:\n",
    "    for d in c['documents']:\n",
    "        d['course'] = c['course']\n",
    "        docs.append(d)\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b6891a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\") \n",
    "\n",
    "EMBEDDING_DIMENSIONS = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c26a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"zoomcamp-faq\"\n",
    "qd_client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e11ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONS,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edbf3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qd_client.delete_collection(collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ddd4d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81174739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=6, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact match on string metadata field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b4460b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    \n",
    "    q_a = doc['question'] + ' ' + doc['text']  # Concatenate question and text for embedding\n",
    "    vector=models.Document(text=q_a, model=model_handle)\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vector_search(question, course=\"data-engineering-zoomcamp\", limit=5):\n",
    "    print(f\"Using Vector Search with filter: {course}. Results limit: {limit}\")\n",
    "    \n",
    "    q_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for point in q_points.points:\n",
    "        results.append(point.payload)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d42c7a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vector Search with filter: dataengineering-zoomcamp. Results limit: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"How to install Kafka?\", course=\"dataengineering-zoomcamp\", limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affe76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM API client\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv /Users/sethurama/DEV/LM/course-llm-zc/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd3a77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = OpenAI()\n",
    "\n",
    "def build_prompt(q_question, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT doesn't contain the answer, output NONE\n",
    "\n",
    "\n",
    "QUESTION: {question} \n",
    "\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer:  {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=q_question, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "# Query the LLM with the modified prompt\n",
    "def query_llm(mod_prompt):\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = [{\"role\": \"user\", \"content\": mod_prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2abe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = query_llm(prompt)\n",
    "    return answer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d1fb6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vector Search with filter: dataengineering-zoomcamp. Results limit: 5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrag\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHow do I run kafka?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mrag\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrag\u001b[39m(query):\n\u001b[32m      2\u001b[39m     search_results = vector_search(query)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     prompt = \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     answer = query_llm(prompt)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mbuild_prompt\u001b[39m\u001b[34m(q_question, search_results)\u001b[39m\n\u001b[32m     15\u001b[39m context = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     context = context + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msection\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mquestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33manswer:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m prompt = prompt_template.format(question=q_question, context=context).strip()\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prompt\n",
      "\u001b[31mTypeError\u001b[39m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "rag(\"How do I run kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-llm-zc-Yowha_Zo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
